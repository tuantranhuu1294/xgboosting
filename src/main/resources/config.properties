#### Some config of XgBoost model
### General parameters
xgboost.param.booster=
xgboost.param.silent=1
xgboost.param.nthread=
xgboost.param.num_pbuffer=
xgboost.param.num_feature=

### Parameters for Tree Booster
xgboost.param.eta=0.05
xgboost.param.gamma=
xgboost.param.max_depth=2
xgboost.param.min_child_weight=
xgboost.param.max_delta_step=
xgboost.param.subsample=
xgboost.param.colsample_bytree=
xgboost.param.colsample_bylevel=
xgboost.param.lambda=
xgboost.param.alpha=
xgboost.param.tree_method=
xgboost.param.sketch_eps=
xgboost.param.scale_pos_weight=
xgboost.param.updater=
xgboost.param.refresh_leaf=
xgboost.param.process_type=
xgboost.param.grow_policy=
xgboost.param.max_leaves=
xgboost.param.max_bins=

### Additional parameters for Dart Booster
xgboost.param.sample_type=
xgboost.param.normalize_type=
xgboost.param.rate_drop=
xgboost.param.one_drop=
xgboost.param.skip_drop=

### Parameters for Linear Booster
xgboost.param.lambda_bias=

### Parameters for Tweedie Regression
xgboost.param.tweedie_variance_power=

### Learning task parameters
## Objective options:
# "reg:linear": linear regression
# "reg:logistic": logistic regression
# "binary:logistic": logistic regression for binary classification, output probability
# "binary:logitraw" --logistic regression for binary classification, output score before logistic transformation
# "count:poisson" --poisson regression for count data, output mean of poisson distribution. max_delta_step is set to 0.7 by default in poisson regression (used to safeguard optimization)
# "multi:softmax" --set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class(number of classes)
# "multi:softprob" --same as softmax, but output a vector of ndata * nclass, which can be further reshaped to ndata, nclass matrix. The result contains predicted probability of each data point belonging to each class.
# "rank:pairwise" --set XGBoost to do ranking task by minimizing the pairwise loss
# "reg:gamma" --gamma regression with log-link. Output is a mean of gamma distribution. It might be useful, e.g., for modeling insurance claims severity, or for any outcome that might be gamma-distributed
# "reg:tweedie" --Tweedie regression with log-link. It might be useful, e.g., for modeling total loss in insurance, or for any outcome that might be Tweedie-distributed.
xgboost.param.objective=multi:softmax
xgboost.param.base_score=
xgboost.param.eval_metric=
xgboost.param.seed=

## Other parameters
xgboost.param.round=100
xgboost.param.tree_limit=3
# Set number of classes when use multi classification objective
xgboost.param.num_class=5